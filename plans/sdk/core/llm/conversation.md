# conversation.ts - 对话管理器逻辑设计

## 需求分析

对话管理器需要提供以下核心能力：
1. 管理对话消息历史
2. 执行单次LLM调用
3. 执行工具调用
4. 提供消息管理接口
5. Token统计

**重要说明**：
- Conversation只是管理LLM交互、工具调用、消息管理
- 主执行引擎始终是现有的图工作流及thread执行引擎
- Conversation不需要自己管理终止等逻辑，始终都是由主执行引擎操作的
- LLM Node、Human Interaction Node、Tool Node托管给Conversation，以免执行引擎需要同时维护提示词消息
- 消息压缩由执行引擎通过事件驱动的方式管理，Conversation只负责检测和触发事件

## 核心职责

1. 消息历史管理
2. 单次LLM调用执行
3. 工具调用执行
4. 消息压缩
5. 消息查询

## 主要属性

- messages: 消息数组，存储对话历史
- llmWrapper: LLM包装器，用于调用LLM
- toolExecutor: 工具执行器，用于执行工具
- tokenLimit: Token限制，触发压缩事件的阈值
- tokenUsage: Token使用统计，从API响应中获取

## 核心方法逻辑

### 1. 初始化

接收配置参数，包括LLM包装器、工具执行器、Token限制等。初始化消息数组，通常以系统消息开始。

### 2. 添加消息

提供添加消息的方法，支持添加用户消息、助手消息、工具消息等。消息会被追加到消息数组末尾。

添加逻辑：
1. 接收消息对象
2. 验证消息格式
3. 将消息追加到messages数组末尾
4. 返回添加后的消息数组长度

### 3. 获取消息

获取当前消息历史。

获取逻辑：
1. 返回messages数组的副本
2. 避免外部修改内部状态

### 4. 清空消息

清空消息历史。

清空逻辑：
1. 清空messages数组
2. 保留系统消息（如果存在）

### 5. 执行单次LLM调用

执行一次LLM调用，不涉及循环逻辑。

执行逻辑：
1. 检查Token数量，如果超过限制则触发压缩事件
2. 获取当前消息数组
3. 调用LLMWrapper的generate方法
4. 传入消息数组和可用工具定义
5. 等待LLM响应
6. 从LLM响应中提取Token使用信息
7. 更新tokenUsage统计
8. 将LLM响应转换为助手消息
9. 添加助手消息到消息历史
10. 返回LLM响应

### 6. 执行工具调用

执行指定的工具调用。

执行逻辑：
1. 从工具调用中提取工具名称和参数
2. 调用工具执行器执行工具
3. 捕获执行过程中的异常
4. 将执行结果或错误信息转换为工具消息
5. 添加工具消息到消息历史
6. 返回工具执行结果

### 7. 批量执行工具调用

执行多个工具调用。

执行逻辑：
1. 遍历所有工具调用
2. 对每个工具调用调用执行工具调用方法
3. 收集所有工具执行结果
4. 返回结果数组

### 8. 检查Token使用情况

检查当前Token使用情况，判断是否需要触发压缩事件。

检查逻辑：
1. 优先从tokenUsage中获取Token统计
2. 如果tokenUsage为空，使用本地计算器估算
3. 如果本地计算器不可用，使用字符数除以2.5估算
4. 比较Token数量与tokenLimit
5. 如果超过限制，触发压缩事件

### 9. 更新Token使用统计

从LLM响应中更新Token使用统计。

更新逻辑：
1. 从LLM响应中提取usage字段
2. 解析prompt_tokens、completion_tokens、total_tokens
3. 更新tokenUsage统计
4. 保存原始API响应的详细信息

### 10. 获取Token使用统计

获取当前Token使用统计。

获取逻辑：
1. 返回tokenUsage对象
2. 包含promptTokens、completionTokens、totalTokens
3. 包含元数据信息

### 11. 获取最近N条消息

获取最近的N条消息。

获取逻辑：
1. 检查N是否大于消息总数
2. 如果大于，返回所有消息
3. 如果不大于，返回最后N条消息
4. 返回消息副本

### 12. 按角色过滤消息

根据角色过滤消息。

过滤逻辑：
1. 遍历所有消息
2. 检查消息角色是否匹配
3. 收集匹配的消息
4. 返回消息数组

## 错误处理

1. LLM调用失败：捕获异常，记录错误，抛出异常
2. 工具执行失败：捕获异常，将错误信息作为工具结果返回
3. Token统计失败：使用备用估算方法
4. 压缩事件触发失败：记录错误，继续执行

## 性能考虑

1. Token统计优先使用API响应，本地计算和估算作为回退方案
2. Token统计使用缓存，避免重复计算
3. 工具调用可以并行执行（如果工具之间无依赖）

## 扩展点

1. 自定义Token统计方法
2. 自定义工具执行逻辑

## 使用场景

1. 在LLM节点中使用：执行LLM调用，管理消息历史
2. 在Human Interaction节点中使用：管理用户交互消息
3. 在Tool节点中使用：执行工具调用，管理工具消息
4. 在应用层中使用：自定义对话逻辑

## 注意事项

1. 消息数组会被修改，需要注意并发访问
2. 工具执行可能会失败，需要妥善处理
3. Conversation不负责压缩逻辑，只负责检测和触发事件
4. Conversation不负责终止逻辑，由主执行引擎控制
5. Conversation不负责循环逻辑，由主执行引擎控制
6. Token统计优先使用API响应，本地计算和估算作为回退方案