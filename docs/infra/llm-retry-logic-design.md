# LLM重试逻辑设计文档

## 文档信息

- **创建日期**: 2025-01-XX
- **设计目标**: 明确LLM模型的重试逻辑设计原则和实现方案
- **核心原则**: 重试逻辑专注于重试本身，不包含模型降级等复杂逻辑

---

## 1. 设计原则

### 1.1 核心原则

**重试逻辑就是重试**

- 重试逻辑的唯一职责是在请求失败时重新尝试
- 重试逻辑不包含模型选择、模型降级、成本控制等业务逻辑
- 重试逻辑应该简单、可预测、易于理解

### 1.2 复用原则

**复用HTTP模块的重试功能**

- LLM请求本质上是HTTP请求
- HTTP模块已经提供了完整的重试机制
- LLM模块应该直接使用HTTP模块的重试功能
- 避免重复实现相同的重试逻辑

### 1.3 分层原则

**清晰的职责分离**

- HTTP层：负责HTTP请求的重试（网络错误、限流等）
- LLM层：负责LLM特定的错误处理（模型不可用、token限制等）
- 业务层：负责模型选择、降级、成本控制等业务逻辑

---

## 2. 重试逻辑设计

### 2.1 HTTP层重试（由HTTP模块负责）

**职责**: 处理HTTP层面的临时性错误

**重试条件**:

1. **网络错误**
   - 连接超时
   - 连接被拒绝
   - DNS解析失败
   - 网络不可达

2. **HTTP状态码**
   - 408 Request Timeout
   - 429 Too Many Requests（限流）
   - 500 Internal Server Error
   - 502 Bad Gateway
   - 503 Service Unavailable
   - 504 Gateway Timeout

3. **其他临时性错误**
   - 读取超时
   - 写入超时

**重试策略**:

- **最大重试次数**: 3次（可配置）
- **延迟策略**: 指数退避（带抖动）
  - 基础延迟: 2秒
  - 退避乘数: 2
  - 最大延迟: 60秒
  - 抖动范围: ±20%

**不重试的情况**:

- 4xx客户端错误（除了429）
- 认证失败（401）
- 权限不足（403）
- 资源不存在（404）
- 请求格式错误（400）

### 2.2 LLM层重试（由LLM客户端负责）

**职责**: 处理LLM特定的临时性错误

**重试条件**:

1. **模型临时不可用**
   - 模型正在维护
   - 模型负载过高
   - 模型服务暂时中断

2. **Token限制**
   - 请求token数超过模型限制（但可以通过截断解决）
   - 响应token数超过模型限制（但可以通过调整参数解决）

3. **配额限制**
   - API调用次数达到限制（但会在短时间内恢复）
   - Token使用量达到限制（但会在短时间内恢复）

**重试策略**:

- **最大重试次数**: 3次（可配置）
- **延迟策略**: 固定延迟 + 抖动
  - 延迟时间: 10秒
  - 抖动范围: ±2秒

**不重试的情况**:

- 模型不存在
- 模型已下线
- API密钥无效
- 账户余额不足
- 请求内容违规

### 2.3 重试流程

**完整重试流程**:

1. **发起请求**
   - LLM客户端调用HTTP模块发送请求

2. **HTTP层重试**
   - 如果遇到HTTP层面的临时性错误，HTTP模块自动重试
   - 重试次数达到上限后，将错误返回给LLM客户端

3. **LLM层判断**
   - LLM客户端接收HTTP模块返回的错误
   - 判断是否是LLM特定的临时性错误

4. **LLM层重试**
   - 如果是LLM特定的临时性错误，LLM客户端进行重试
   - 重试前可能需要调整请求参数（如截断文本）
   - 重试次数达到上限后，将错误返回给调用方

5. **返回结果**
   - 如果重试成功，返回正常结果
   - 如果重试失败，返回错误信息

---

## 3. 错误分类

### 3.1 可重试错误

**HTTP层可重试错误**:
- 网络连接错误
- 网络超时错误
- HTTP 429（限流）
- HTTP 5xx（服务器错误）

**LLM层可重试错误**:
- 模型临时不可用
- Token限制（可调整）
- 配额限制（临时）

### 3.2 不可重试错误

**HTTP层不可重试错误**:
- HTTP 400（请求格式错误）
- HTTP 401（认证失败）
- HTTP 403（权限不足）
- HTTP 404（资源不存在）

**LLM层不可重试错误**:
- 模型不存在
- 模型已下线
- API密钥无效
- 账户余额不足
- 请求内容违规

---

## 4. 配置设计

### 4.1 HTTP重试配置

**配置项**:
- 最大重试次数
- 基础延迟（毫秒）
- 最大延迟（毫秒）
- 退避乘数
- 是否启用抖动

**配置位置**: 全局配置文件（configs/global.toml）

### 4.2 LLM重试配置

**配置项**:
- 最大重试次数
- 延迟时间（秒）
- 是否启用Token截断
- 最大Token数

**配置位置**: LLM配置文件（configs/llm.toml）

---

## 5. 实现方案

### 5.1 HTTP层实现

**使用现有的RetryHandler**

- HTTP模块已经提供了完整的重试机制
- LLM客户端直接使用HttpClient发送请求
- HttpClient内部使用RetryHandler进行重试
- 无需额外实现

### 5.2 LLM层实现

**在LLM客户端中实现简单的重试逻辑**

1. **捕获HTTP层返回的错误**
   - 检查错误类型和错误信息
   - 判断是否是LLM特定的临时性错误

2. **执行重试**
   - 如果是可重试错误，等待指定时间后重试
   - 重试前可能需要调整请求参数
   - 重试次数达到上限后，返回错误

3. **记录重试信息**
   - 记录重试次数
   - 记录重试原因
   - 记录重试结果

### 5.3 不需要实现的功能

**以下功能不属于重试逻辑**:

- 模型降级
- 模型选择
- 成本控制
- 会话记录
- 提供商切换

这些功能应该在业务层实现，而不是在重试逻辑中实现。

---

## 6. 与HTTP模块的关系

### 6.1 依赖关系

- LLM客户端依赖HttpClient
- HttpClient依赖RetryHandler
- LLM重试逻辑在HTTP重试逻辑之上

### 6.2 职责划分

- **HTTP模块**: 负责HTTP请求的重试
- **LLM模块**: 负责LLM特定的错误处理和重试
- **业务层**: 负责模型选择、降级、成本控制等

### 6.3 配置映射

- LLM重试配置独立于HTTP重试配置
- 两者可以有不同的重试次数和延迟策略
- LLM重试在HTTP重试失败后执行

---

## 7. 示例场景

### 7.1 网络错误场景

1. LLM客户端发起请求
2. 网络连接超时
3. HTTP模块检测到超时错误
4. HTTP模块自动重试（最多3次）
5. 重试成功，返回结果

### 7.2 限流场景

1. LLM客户端发起请求
2. 返回HTTP 429（限流）
3. HTTP模块检测到限流错误
4. HTTP模块等待后重试（最多3次）
5. 重试成功，返回结果

### 7.3 模型不可用场景

1. LLM客户端发起请求
2. 返回HTTP 200，但响应中包含模型不可用错误
3. HTTP模块认为请求成功，不进行重试
4. LLM客户端检测到模型不可用错误
5. LLM客户端等待后重试（最多2次）
6. 重试成功，返回结果

### 7.4 模型不存在场景

1. LLM客户端发起请求
2. 返回HTTP 404（模型不存在）
3. HTTP模块认为不可重试，不进行重试
4. LLM客户端检测到模型不存在错误
5. LLM客户端认为不可重试，不进行重试
6. 返回错误信息

---

## 8. 监控和日志

### 8.1 监控指标

- HTTP重试次数
- HTTP重试成功率
- LLM重试次数
- LLM重试成功率
- 平均重试延迟
- 重试原因分布

### 8.2 日志记录

- 记录每次重试的详细信息
- 包括重试次数、重试原因、重试延迟、重试结果
- 便于问题排查和性能优化

---

## 9. 测试策略

### 9.1 单元测试

- 测试HTTP重试逻辑
- 测试LLM重试逻辑
- 测试错误分类逻辑
- 测试配置映射逻辑

### 9.2 集成测试

- 测试HTTP层和LLM层的集成
- 测试各种错误场景
- 测试重试流程

### 9.3 性能测试

- 测试重试对性能的影响
- 测试重试延迟的准确性
- 测试重试次数的限制

---

## 10. 总结

### 10.1 核心要点

1. **重试逻辑专注于重试本身**
   - 不包含模型降级、成本控制等业务逻辑
   - 保持简单、可预测、易于理解

2. **复用HTTP模块的重试功能**
   - LLM请求本质上是HTTP请求
   - HTTP模块已经提供了完整的重试机制
   - 避免重复实现

3. **清晰的职责分离**
   - HTTP层：负责HTTP请求的重试
   - LLM层：负责LLM特定的错误处理
   - 业务层：负责模型选择、降级、成本控制

### 10.2 实施建议

1. **简化LLM重试配置**
   - 只保留必要的配置项
   - 移除未使用的复杂配置

2. **统一错误处理**
   - 明确错误分类
   - 统一错误处理流程

3. **完善监控和日志**
   - 记录重试信息
   - 监控重试指标

4. **充分测试**
   - 覆盖各种错误场景
   - 验证重试逻辑的正确性

---

## 附录

### A. 相关文件

- `src/infrastructure/common/http/retry-handler.ts`
- `src/infrastructure/common/http/http-client.ts`
- `src/infrastructure/llm/clients/base-llm-client.ts`
- `src/infrastructure/llm/clients/openai-chat-client.ts`

### B. 变更历史

| 日期 | 版本 | 变更说明 | 作者 |
|------|------|----------|------|
| 2025-01-XX | 1.0 | 初始版本 | - |