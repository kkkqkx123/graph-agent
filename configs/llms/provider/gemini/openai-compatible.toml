# Gemini OpenAI兼容API配置
# 继承自 common.toml，只覆盖需要修改的参数

# 基础配置
provider = "gemini"
model_type = "gemini"
clientType = "openai-compatible"

# API配置 - 使用OpenAI兼容端点
base_url = "https://generativelanguage.googleapis.com/v1beta/openai"
api_version = "v1beta"
api_key = "${GEMINI_API_KEY}"
api_format = "chat_completion"

# HTTP客户端配置
timeout = 30
max_retries = 3
retry_delay = 1.0
backoff_factor = 2.0
pool_connections = 10

# 默认请求头
[default_headers]
Content-Type = "application/json"
User-Agent = "Gemini-OpenAI-Client/1.0"

# 功能支持
[features]
function_calling = true
streaming = true
vision = true
audio = true
video = true
thinking_budget = true
cached_content = true

# 默认参数
[defaults]
temperature = 0.7
max_tokens = 8192
top_p = 0.95
frequency_penalty = 0.0
presence_penalty = 0.0
stream = false

# 错误处理
[error_handling]
retry_on_rate_limit = true
retry_on_server_error = true
max_retry_backoff = 60.0

# 支持的模型列表
models = [
    "gemini-2.5-pro",
    "gemini-2.5-flash",
    "gemini-2.5-flash-lite",
    "gemini-3.0-pro",
    "gemini-3.0-flash",
]

# 限流配置
[rate_limiting]
requests_per_minute = 60
tokens_per_minute = 32000

# 元数据
[metadata]
provider = "google"
version = "1.0"
description = "Gemini OpenAI兼容API配置"
api_type = "openai-compatible"
supported_features = [
    "function_calling",
    "streaming",
    "vision",
    "audio",
    "video",
    "thinking_budget",
    "cached_content",
]
